{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab8bf9f-5aff-4547-b926-dd7d6223c229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables dropped successfully.\n",
      "Tables created successfully.\n"
     ]
    }
   ],
   "source": [
    "!python create_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1dd32d8-2b17-4da4-a1b2-d17012101586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Redshift connection established OK.\n",
      "Start loading data from S3 to AWS Reshift tables...\n",
      "------------------\n",
      "Processing query: \n",
      "    COPY staging_events FROM 's3://udacity-dend-project-nandni/data/log_data'\n",
      "    credentials 'aws_iam_role=arn:aws:iam::474668386387:role/myRedshiftRole'\n",
      "    format as json 's3://udacity-dend-project-nandni/data/log_json_path.json'\n",
      "    STATUPDATE ON\n",
      "    region 'us-west-2';\n",
      "\n",
      "------------------\n",
      "\n",
      "    COPY staging_events FROM 's3://udacity-dend-project-nandni/data/log_data'\n",
      "    credentials 'aws_iam_role=arn:aws:iam::474668386387:role/myRedshiftRole'\n",
      "    format as json 's3://udacity-dend-project-nandni/data/log_json_path.json'\n",
      "    STATUPDATE ON\n",
      "    region 'us-west-2';\n",
      " processed OK.\n",
      "------------------\n",
      "Processing query: \n",
      "    COPY staging_songs FROM 's3://udacity-dend-project-nandni/data/song_data/'\n",
      "    credentials 'aws_iam_role=arn:aws:iam::474668386387:role/myRedshiftRole'\n",
      "    format as json 'auto'\n",
      "    ACCEPTINVCHARS AS '^'\n",
      "    STATUPDATE ON\n",
      "    region 'us-west-2';\n",
      "\n",
      "------------------\n",
      "\n",
      "    COPY staging_songs FROM 's3://udacity-dend-project-nandni/data/song_data/'\n",
      "    credentials 'aws_iam_role=arn:aws:iam::474668386387:role/myRedshiftRole'\n",
      "    format as json 'auto'\n",
      "    ACCEPTINVCHARS AS '^'\n",
      "    STATUPDATE ON\n",
      "    region 'us-west-2';\n",
      " processed OK.\n",
      "All files COPIED OK.\n",
      "Start inserting data from staging tables into analysis tables...\n",
      "------------------\n",
      "Processing query: \n",
      "    INSERT INTO songplays (             start_time,\n",
      "                                        user_id,\n",
      "                                        level,\n",
      "                                        song_id,\n",
      "                                        artist_id,\n",
      "                                        session_id,\n",
      "                                        location,\n",
      "                                        user_agent)\n",
      "    SELECT  DISTINCT TIMESTAMP 'epoch' + se.ts/1000                 * INTERVAL '1 second'   AS start_time,\n",
      "            se.userId                   AS user_id,\n",
      "            se.level                    AS level,\n",
      "            ss.song_id                  AS song_id,\n",
      "            ss.artist_id                AS artist_id,\n",
      "            se.sessionId                AS session_id,\n",
      "            se.location                 AS location,\n",
      "            se.userAgent                AS user_agent\n",
      "    FROM staging_events AS se\n",
      "    JOIN staging_songs AS ss\n",
      "        ON (se.artist = ss.artist_name)\n",
      "    WHERE se.page = 'NextSong';\n",
      "\n",
      "\n",
      "    INSERT INTO songplays (             start_time,\n",
      "                                        user_id,\n",
      "                                        level,\n",
      "                                        song_id,\n",
      "                                        artist_id,\n",
      "                                        session_id,\n",
      "                                        location,\n",
      "                                        user_agent)\n",
      "    SELECT  DISTINCT TIMESTAMP 'epoch' + se.ts/1000                 * INTERVAL '1 second'   AS start_time,\n",
      "            se.userId                   AS user_id,\n",
      "            se.level                    AS level,\n",
      "            ss.song_id                  AS song_id,\n",
      "            ss.artist_id                AS artist_id,\n",
      "            se.sessionId                AS session_id,\n",
      "            se.location                 AS location,\n",
      "            se.userAgent                AS user_agent\n",
      "    FROM staging_events AS se\n",
      "    JOIN staging_songs AS ss\n",
      "        ON (se.artist = ss.artist_name)\n",
      "    WHERE se.page = 'NextSong';\n",
      " processed OK.\n",
      "------------------\n",
      "Processing query: \n",
      "    INSERT INTO users (                 user_id,\n",
      "                                        first_name,\n",
      "                                        last_name,\n",
      "                                        gender,\n",
      "                                        level)\n",
      "    SELECT  DISTINCT se.userId          AS user_id,\n",
      "            se.firstName                AS first_name,\n",
      "            se.lastName                 AS last_name,\n",
      "            se.gender                   AS gender,\n",
      "            se.level                    AS level\n",
      "    FROM staging_events AS se\n",
      "    WHERE se.page = 'NextSong';\n",
      "\n",
      "\n",
      "    INSERT INTO users (                 user_id,\n",
      "                                        first_name,\n",
      "                                        last_name,\n",
      "                                        gender,\n",
      "                                        level)\n",
      "    SELECT  DISTINCT se.userId          AS user_id,\n",
      "            se.firstName                AS first_name,\n",
      "            se.lastName                 AS last_name,\n",
      "            se.gender                   AS gender,\n",
      "            se.level                    AS level\n",
      "    FROM staging_events AS se\n",
      "    WHERE se.page = 'NextSong';\n",
      " processed OK.\n",
      "------------------\n",
      "Processing query: \n",
      "    INSERT INTO songs (                 song_id,\n",
      "                                        title,\n",
      "                                        artist_id,\n",
      "                                        year,\n",
      "                                        duration)\n",
      "    SELECT  DISTINCT ss.song_id         AS song_id,\n",
      "            ss.title                    AS title,\n",
      "            ss.artist_id                AS artist_id,\n",
      "            ss.year                     AS year,\n",
      "            ss.duration                 AS duration\n",
      "    FROM staging_songs AS ss;\n",
      "\n",
      "\n",
      "    INSERT INTO songs (                 song_id,\n",
      "                                        title,\n",
      "                                        artist_id,\n",
      "                                        year,\n",
      "                                        duration)\n",
      "    SELECT  DISTINCT ss.song_id         AS song_id,\n",
      "            ss.title                    AS title,\n",
      "            ss.artist_id                AS artist_id,\n",
      "            ss.year                     AS year,\n",
      "            ss.duration                 AS duration\n",
      "    FROM staging_songs AS ss;\n",
      " processed OK.\n",
      "------------------\n",
      "Processing query: \n",
      "    INSERT INTO artists (               artist_id,\n",
      "                                        name,\n",
      "                                        location,\n",
      "                                        latitude,\n",
      "                                        longitude)\n",
      "    SELECT  DISTINCT ss.artist_id       AS artist_id,\n",
      "            ss.artist_name              AS name,\n",
      "            ss.artist_location          AS location,\n",
      "            ss.artist_latitude          AS latitude,\n",
      "            ss.artist_longitude         AS longitude\n",
      "    FROM staging_songs AS ss;\n",
      "\n",
      "\n",
      "    INSERT INTO artists (               artist_id,\n",
      "                                        name,\n",
      "                                        location,\n",
      "                                        latitude,\n",
      "                                        longitude)\n",
      "    SELECT  DISTINCT ss.artist_id       AS artist_id,\n",
      "            ss.artist_name              AS name,\n",
      "            ss.artist_location          AS location,\n",
      "            ss.artist_latitude          AS latitude,\n",
      "            ss.artist_longitude         AS longitude\n",
      "    FROM staging_songs AS ss;\n",
      " processed OK.\n",
      "------------------\n",
      "Processing query: \n",
      "    INSERT INTO time (                  start_time,\n",
      "                                        hour,\n",
      "                                        day,\n",
      "                                        week,\n",
      "                                        month,\n",
      "                                        year,\n",
      "                                        weekday)\n",
      "    SELECT  DISTINCT TIMESTAMP 'epoch' + se.ts/1000                 * INTERVAL '1 second'        AS start_time,\n",
      "            EXTRACT(hour FROM start_time)    AS hour,\n",
      "            EXTRACT(day FROM start_time)     AS day,\n",
      "            EXTRACT(week FROM start_time)    AS week,\n",
      "            EXTRACT(month FROM start_time)   AS month,\n",
      "            EXTRACT(year FROM start_time)    AS year,\n",
      "            EXTRACT(week FROM start_time)    AS weekday\n",
      "    FROM    staging_events                   AS se\n",
      "    WHERE se.page = 'NextSong';\n",
      "\n",
      "\n",
      "    INSERT INTO time (                  start_time,\n",
      "                                        hour,\n",
      "                                        day,\n",
      "                                        week,\n",
      "                                        month,\n",
      "                                        year,\n",
      "                                        weekday)\n",
      "    SELECT  DISTINCT TIMESTAMP 'epoch' + se.ts/1000                 * INTERVAL '1 second'        AS start_time,\n",
      "            EXTRACT(hour FROM start_time)    AS hour,\n",
      "            EXTRACT(day FROM start_time)     AS day,\n",
      "            EXTRACT(week FROM start_time)    AS week,\n",
      "            EXTRACT(month FROM start_time)   AS month,\n",
      "            EXTRACT(year FROM start_time)    AS year,\n",
      "            EXTRACT(week FROM start_time)    AS weekday\n",
      "    FROM    staging_events                   AS se\n",
      "    WHERE se.page = 'NextSong';\n",
      " processed OK.\n",
      "All files INSERTED OK.\n"
     ]
    }
   ],
   "source": [
    "!python etl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4abf7-5655-4515-ab35-89cfafe76638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
